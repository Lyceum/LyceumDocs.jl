<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>MPPI · Lyceum</title><link rel="canonical" href="https://docs.lyceum.ml/dev/lyceumai/algorithms/mppi/index.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link href="../../../assets/custom.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="Lyceum logo"/></a><div class="docs-package-name"><span class="docs-autofit">Lyceum</span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">LyceumBase</span><ul><li><a class="tocitem" href="../../../lyceumbase/abstractenvironment/">AbstractEnvironment</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../../examples/example_howto/">Running Examples Locally</a></li><li><a class="tocitem" href="../../../examples/humanoid/">Creating a MuJoCo Environment</a></li><li><a class="tocitem" href="../../../examples/NPG/">Learning a Control Policy</a></li><li><a class="tocitem" href="../../../examples/visualize/">Using the Visualizer</a></li></ul></li><li><span class="tocitem">LyceumAI</span><ul><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../models/policies/">Policies</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox" checked/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Algorithms</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../naturalpolicygradient/">Natural Policy Gradient</a></li><li class="is-active"><a class="tocitem" href>MPPI</a></li></ul></li></ul></li><li><span class="tocitem">LyceumMuJoCo</span><ul><li><a class="tocitem" href="../../../lyceummujoco/lyceummujoco/">LyceumMuJoCo</a></li><li><a class="tocitem" href="../../../lyceummujoco/environments/">Environments</a></li></ul></li><li><span class="tocitem">LyceumMuJoCoViz</span><ul><li><a class="tocitem" href="../../../lyceummujocoviz/lyceummujocoviz/">LyceumMuJoCoViz</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">LyceumAI</a></li><li><a class="is-disabled">Algorithms</a></li><li class="is-active"><a href>MPPI</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>MPPI</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Model-Predictive-Path-Integral-Control-1"><a class="docs-heading-anchor" href="#Model-Predictive-Path-Integral-Control-1">Model-Predictive Path Integral Control</a><a class="docs-heading-anchor-permalink" href="#Model-Predictive-Path-Integral-Control-1" title="Permalink"></a></h1><p>Implements Model-Predictive Path Integral Control, a stochastic sampling based model predictive control method. For further information, see the following papers:</p><ul><li><a href="https://homes.cs.washington.edu/~bboots/files/InformationTheoreticMPC.pdf">Information Theoretic MPC for Model-Based Reinforcement Learning</a></li><li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487277">Aggressive Driving with Model Predictive Path Integral Control</a></li></ul><article class="docstring"><header><a class="docstring-binding" id="LyceumAI.MPPI" href="#LyceumAI.MPPI"><code>LyceumAI.MPPI</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">struct MPPI{DT&lt;:AbstractFloat, nu, Covar&lt;:AbstractArray{DT&lt;:AbstractFloat,2}, Value, Env, Init, Obs, State}</code></pre><pre><code class="language-none">MPPI{DT&lt;:AbstractFloat}(args...; kwargs...) -&gt; MPPI
MPPI(args...; kwargs...) -&gt; MPPI</code></pre><p>Construct an instance of  <code>MPPI</code> with <code>args</code> and <code>kwargs</code>, where <code>DT &lt;: AbstractFloat</code> is the element type used for pre-allocated buffers, which defaults to Float32.</p><p>In the following explanation of the <code>MPPI</code> constructor, we use the following notation:</p><ul><li><code>U::Matrix</code>: the canonical control vector <span>$(u_{1}, u_{2}, \dots, u_{H})$</span>, where   <code>size(U) == (length(actionspace(env)), H)</code>.</li></ul><p><strong>Keywords</strong></p><ul><li><code>env_tconstructor</code>: a function with signature <code>env_tconstructor(n)</code> that returns <code>n</code>   instances of <code>T</code>, where <code>T &lt;: AbstractEnvironment</code>.</li><li><code>H::Integer</code>: Length of sampled trajectories.</li><li><code>K::Integer</code>: Number of trajectories to sample.</li><li><code>covar::AbstractMatrix</code>: The covariance matrix for the Normal distribution from which   control pertubations are sampled from.</li><li><code>gamma::Real</code>: Reward discount, applied as <code>gamma^(t - 1) * reward[t]</code>.</li><li><code>lambda::Real</code>: Temperature parameter for the exponential reweighting of sampled   trajectories. In the limit that lambda approaches 0, <code>U</code> is set to the highest reward   trajectory. Conversely, as <code>lambda</code> approaches infinity, <code>U</code> is computed as the   unweighted-average of the samples trajectories.</li><li><code>value</code>: a function mapping observations to scalar rewards, with the signature   <code>value(obs::AbstractVector) --&gt; reward::Real</code></li><li><code>initfn!</code>: A function with the signature <code>initfn!(U::Matrix)</code> used for   re-initializing <code>U</code> after shifting it. Defaults to setting the last   element of <code>U</code> to 0.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LyceumBase.getaction!-Tuple{AbstractArray{T,1} where T,Any,LyceumAI.MPPI}" href="#LyceumBase.getaction!-Tuple{AbstractArray{T,1} where T,Any,LyceumAI.MPPI}"><code>LyceumBase.getaction!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">getaction!(action, state, m; nthreads)
</code></pre><p>Starting from the environment&#39;s <code>state</code>, perform one step of the MPPI algorithm and store the resulting action in <code>action</code>. The trajectory sampling portion of MPPI is done in parallel using <code>nthreads</code> threads.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LyceumBase.reset!-Tuple{LyceumAI.MPPI}" href="#LyceumBase.reset!-Tuple{LyceumAI.MPPI}"><code>LyceumBase.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reset!(m::LyceumAI.MPPI) -&gt; LyceumAI.MPPI
</code></pre><p>Resets the canonical control vector to zeros.</p></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../naturalpolicygradient/">« Natural Policy Gradient</a><a class="docs-footer-nextpage" href="../../../lyceummujoco/lyceummujoco/">LyceumMuJoCo »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 12 February 2020 00:48">Wednesday 12 February 2020</span>. Using Julia version 1.3.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
