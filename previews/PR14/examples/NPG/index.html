<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Learning a control policy · Lyceum</title><link rel="canonical" href="https://docs.lyceum.ml/dev/examples/NPG/index.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Lyceum</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../MPPI/">Running a simple controller</a></li><li class="is-active"><a class="tocitem" href>Learning a control policy</a><ul class="internal"><li><a class="tocitem" href="#Policy-Gradient-Example-1"><span>Policy Gradient Example</span></a></li><li><a class="tocitem" href="#Policy-Gradient-Components-1"><span>Policy Gradient Components</span></a></li><li><a class="tocitem" href="#Running-Experiments-1"><span>Running Experiments</span></a></li></ul></li><li><a class="tocitem" href="../visualize/">Visualizing Results</a></li><li><a class="tocitem" href="../humanoid/">Creating a MuJoCo Environment</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Learning a control policy</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Learning a control policy</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/Lyceum/LyceumDocs.jl/blob/master/docs/src/examples/NPG.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><div class="admonition is-info"><header class="admonition-header">Running examples locally</header><div class="admonition-body"><p>This example and more are also available as Julia scripts and Jupyter notebooks.</p><p>See <a href="https://github.com/Lyceum/LyceumDocs.jl/blob/master/example_howto.md">the how-to page</a> for more information.</p></div></div><h1 id="Learning-a-control-policy-1"><a class="docs-heading-anchor" href="#Learning-a-control-policy-1">Learning a control policy</a><a class="docs-heading-anchor-permalink" href="#Learning-a-control-policy-1" title="Permalink"></a></h1><h2 id="Policy-Gradient-Example-1"><a class="docs-heading-anchor" href="#Policy-Gradient-Example-1">Policy Gradient Example</a><a class="docs-heading-anchor-permalink" href="#Policy-Gradient-Example-1" title="Permalink"></a></h2><p>In this example we walk through the process of setting up an experiment that runs <a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf">Natural Policy Gradient</a>, or more recently <a href="https://arxiv.org/abs/1703.02660">in this work</a>. This is an on-policy reinforcement learning method that is comparable to TRPO, PPO, and other policy gradient methods.</p><p>First, let&#39;s go head and grab all the dependencies</p><pre><code class="language-julia">using LinearAlgebra, Random, Statistics # From Stdlib
using LyceumAI         # For the NPG controller
using LyceumMuJoCo     # For the Hopper environment
using LyceumBase.Tools # For the ControllerIterator discussed below
using Flux             # For our Neural Network Needs
using Flux: glorot_uniform
using UniversalLogger
using Plots</code></pre><p>We first configure and instantiate of our <code>Hopper</code> environment to grab useful environment specific values such as the size of the observation and action vectors.</p><pre><code class="language-julia">env = LyceumMuJoCo.HopperV2();
dobs, dact = length(obsspace(env)), length(actionspace(env));</code></pre><h2 id="Policy-Gradient-Components-1"><a class="docs-heading-anchor" href="#Policy-Gradient-Components-1">Policy Gradient Components</a><a class="docs-heading-anchor-permalink" href="#Policy-Gradient-Components-1" title="Permalink"></a></h2><p>Policy Gradient methods require a policy: a function that takes in the state/observations of the agent, and output an action i.e. <code>action = π(obs)</code>. In much of Deep RL, the policy takes the form of a neural network which can be built on top of the <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> library. The network below is two layers, mapping from our observation space to 32 hidden units, to the second 32 hidden units layer, before emitting a vector of actions. The activations are all tanh functions, and we initialize the network with Glorot Uniform initializations. The policy is more than just a feed forward nerual network, however. It&#39;s treated as a stochastic variable, and thus we track the log of the standard deviation of noise to apply to the action sampling; this is final zero vector of size &#39;dact&#39;.</p><pre><code class="language-julia">policy = DiagGaussianPolicy(
    multilayer_perceptron(
        dobs,
        32,
        32,
        dact;
        σ = tanh,
        initb = glorot_uniform,
        initb_final = glorot_uniform,
    ),
    zeros(dact),
)</code></pre><pre><code class="language-none">LyceumAI.DiagGaussianPolicy{true,Flux.Chain{Tuple{Flux.Dense{typeof(tanh),Array{Float32,2},Array{Float32,1}},Flux.Dense{typeof(tanh),Array{Float32,2},Array{Float32,1}},Flux.Dense{typeof(identity),Array{Float32,2},Array{Float32,1}}}},Array{Float64,1}}(Chain(Dense(11, 32, tanh), Dense(32, 32, tanh), Dense(32, 3)), [0.0, 0.0, 0.0])</code></pre><p>Convert the weights of our policy to <code>Float32</code> rather than the default Float64 for performance.</p><pre><code class="language-julia">policy = Flux.paramtype(Float32, policy);</code></pre><p>This NPG implementation uses <a href="https://arxiv.org/pdf/1506.02438.pdf">Generalized Advantaged Estimation</a>, which requires an estimate of the value function <code>V(state)</code>, which we represent using a 2-layer, feedforward neural network.</p><pre><code class="language-julia">value = multilayer_perceptron(
    dobs,
    128,
    128,
    1;
    σ = Flux.relu,
    initb = glorot_uniform,
    initb_final = glorot_uniform,
)
value = Flux.paramtype(Float32, value);</code></pre><p>FluxTrainer is an iterator that loops on the Flux object provided. The result at each loop is passed to stopcb below, so you can quit after a number of epochs, convergence, or other criteria; here it&#39;s capped at two epochs as a lambda function.</p><pre><code class="language-julia">valueloss(bl, X, Y) = Flux.mse(vec(bl(X)), vec(Y))
valuetrainer = FluxTrainer(
    optimiser = ADAM(1e-3),
    szbatch = 64,
    lossfn = valueloss,
    stopcb = s -&gt; s.nepochs &gt; 2,
);</code></pre><p>The <code>NaturalPolicyGradient</code> iterator is a type that pre-allocates all necesary data structures and performs one gradient update to the policy at each iteration. We first pass in a constructor that given <code>n</code> returns <code>n</code> instances of <code>LyceumMuJoCo.HopperV2</code>, all sharing the same <code>jlModel</code>, to allow for performant sampling from our policy. We then pass in the <code>policy</code>, <code>value</code>, and <code>valuetrainer</code> instances constructed above and override a few of the default <code>NaturalPolicyGradient</code> parameters: <code>gamma</code>, <code>gaelambda</code>, and <code>norm_step_size</code>. Finally, we set the max trajectory length <code>Hmax</code> and total number of samples per iteration, <code>N</code>. Under the hood, <code>NaturalPolicyGradient</code> will use approximately <code>div(N, Hmax)</code> threads to perform the sampling.</p><pre><code class="language-julia">npg = NaturalPolicyGradient(
    n -&gt; tconstruct(LyceumMuJoCo.HopperV2, n),
    policy,
    value,
    valuetrainer;
    gamma = 0.995,
    gaelambda = 0.97,
    norm_step_size = 0.05,
    Hmax = 1000,
    N = 10000,
);</code></pre><h2 id="Running-Experiments-1"><a class="docs-heading-anchor" href="#Running-Experiments-1">Running Experiments</a><a class="docs-heading-anchor-permalink" href="#Running-Experiments-1" title="Permalink"></a></h2><p>Finally, let&#39;s spin on our iterator 200 times, plotting every 20 iterations. This lets us break out of the loop if certain conditions are met, or re-start training manually if needed. We of course wish to track results, so we create an <code>Experiment</code> to which we can save data. We also have useful timing information displayed every 20 iterations to understand CPU performance.</p><pre><code class="language-julia">exper = Experiment(&quot;/tmp/hopper_example.jlso&quot;, overwrite = true)
lg = ULogger() # walks, talks, and acts like a Julia logger. See the docs on UniversalLogger for more info.
for (i, state) in enumerate(npg)
    if i &gt; 200
        # serialize some stuff and quit
        exper[:policy] = npg.policy
        exper[:value] = npg.value
        exper[:etype] = LyceumMuJoCo.HopperV2
        exper[:meanstates] = state.meanbatch
        exper[:stocstates] = state.stocbatch
        break
    end

    # log everything in `state` except meanbatch and stocbatch
    push!(lg, :algstate, filter_nt(state, exclude = (:meanbatch, :stocbatch)))

    if mod(i, 20) == 0
        x = lg[:algstate]
        # The following are helper functions for plotting to the terminal.
        # The first plot displays the eval function for our stochastic
        # and mean policy rollouts.
        display(expplot(
            Line(x[:stocterminal_eval], &quot;StocLastE&quot;),
            Line(x[:meanterminal_eval], &quot;MeanLastE&quot;),
            title = &quot;Evaluation Score, Iter=$i&quot;,
            width = 60,
            height = 8,
        ))
        # While the second one similarly plots the reward.
        display(expplot(
            Line(x[:stoctraj_reward], &quot;StocR&quot;),
            Line(x[:meantraj_reward], &quot;MeanR&quot;),
            title = &quot;Reward, Iter=$i&quot;,
            width = 60,
            height = 8,
        ))

        # The following are timing values for various parts of the Natural Policy Gradient
        # algorithm at the last iteration, useful for finding performance bottlenecks in the algorithm.
        println(&quot;elapsed_sampled  = &quot;, state.elapsed_sampled)
        println(&quot;elapsed_gradll   = &quot;, state.elapsed_gradll)
        println(&quot;elapsed_vpg      = &quot;, state.elapsed_vpg)
        println(&quot;elapsed_cg       = &quot;, state.elapsed_cg)
        println(&quot;elapsed_valuefit = &quot;, state.elapsed_valuefit)
    end
end</code></pre><pre><code class="language-none">┌ Warning: The specified values for size and/or count will result in 16 unused data points
└ @ MLDataPattern ~/.julia/packages/MLDataPattern/mX21p/src/dataview.jl:204
elapsed_sampled  = 0.356972549
elapsed_gradll   = 1.321162055
elapsed_vpg      = 0.004272739
elapsed_cg       = 0.081314349
elapsed_valuefit = 0.82521092
elapsed_sampled  = 0.325923456
elapsed_gradll   = 1.317450203
elapsed_vpg      = 0.004031525
elapsed_cg       = 0.07556635
elapsed_valuefit = 0.84158741
elapsed_sampled  = 0.315498965
elapsed_gradll   = 1.387344274
elapsed_vpg      = 0.00398062
elapsed_cg       = 0.085576562
elapsed_valuefit = 1.082672967
elapsed_sampled  = 0.316112096
elapsed_gradll   = 1.354478274
elapsed_vpg      = 0.004924443
elapsed_cg       = 0.07947151
elapsed_valuefit = 0.824258173
elapsed_sampled  = 0.348575988
elapsed_gradll   = 1.3440814
elapsed_vpg      = 0.004596031
elapsed_cg       = 0.076896978
elapsed_valuefit = 0.875775335
elapsed_sampled  = 0.320750908
elapsed_gradll   = 1.361059682
elapsed_vpg      = 0.00395301
elapsed_cg       = 0.075164886
elapsed_valuefit = 0.843286818
elapsed_sampled  = 0.323923049
elapsed_gradll   = 1.353525357
elapsed_vpg      = 0.003877906
elapsed_cg       = 0.082231644
elapsed_valuefit = 0.81579298
elapsed_sampled  = 0.324836554
elapsed_gradll   = 1.342010147
elapsed_vpg      = 0.003778402
elapsed_cg       = 0.076933472
elapsed_valuefit = 0.917718425
elapsed_sampled  = 0.337342387
elapsed_gradll   = 1.370536104
elapsed_vpg      = 0.003972206
elapsed_cg       = 0.075538511
elapsed_valuefit = 0.95237937
elapsed_sampled  = 0.306866402
elapsed_gradll   = 1.319436227
elapsed_vpg      = 0.004077907
elapsed_cg       = 0.07879958
elapsed_valuefit = 1.044473173</code></pre><p>Let&#39;s go ahead and plot the final reward trajectory for our stochastic and mean policies to see how we did.</p><pre><code class="language-julia">plot!(
    plot(lg[:algstate][:meantraj_reward], label = &quot;Mean Policy&quot;, title = &quot;HopperV2 Reward&quot;),
    lg[:algstate][:stoctraj_reward],
    label = &quot;Stochastic Policy&quot;,
)</code></pre><?xml version="1.0" encoding="utf-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600">
<defs>
  <clipPath id="clip8400">
    <rect x="0" y="0" width="2400" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip8400)" d="
M0 1600 L2400 1600 L2400 0 L0 0  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip8401">
    <rect x="480" y="0" width="1681" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip8400)" d="
M86.9921 1521.01 L2352.76 1521.01 L2352.76 62.9921 L86.9921 62.9921  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip8402">
    <rect x="86" y="62" width="2267" height="1459"/>
  </clipPath>
</defs>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  140.376,1521.01 140.376,62.9921 
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  677.44,1521.01 677.44,62.9921 
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1214.5,1521.01 1214.5,62.9921 
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1751.57,1521.01 1751.57,62.9921 
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2288.63,1521.01 2288.63,62.9921 
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,1483.02 2352.76,1483.02 
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,1090.09 2352.76,1090.09 
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,697.163 2352.76,697.163 
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,304.235 2352.76,304.235 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1521.01 2352.76,1521.01 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1521.01 86.9921,62.9921 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  140.376,1521.01 140.376,1503.51 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  677.44,1521.01 677.44,1503.51 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1214.5,1521.01 1214.5,1503.51 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1751.57,1521.01 1751.57,1503.51 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  2288.63,1521.01 2288.63,1503.51 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1483.02 114.181,1483.02 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1090.09 114.181,1090.09 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,697.163 114.181,697.163 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,304.235 114.181,304.235 
  "/>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 140.376, 1575.01)" x="140.376" y="1575.01">0</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 677.44, 1575.01)" x="677.44" y="1575.01">50</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 1214.5, 1575.01)" x="1214.5" y="1575.01">100</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 1751.57, 1575.01)" x="1751.57" y="1575.01">150</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 2288.63, 1575.01)" x="2288.63" y="1575.01">200</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 1500.52)" x="62.9921" y="1500.52">0</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 1107.59)" x="62.9921" y="1107.59">1000</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 714.663)" x="62.9921" y="714.663">2000</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 321.735)" x="62.9921" y="321.735">3000</text>
</g>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;" transform="rotate(0, 1219.87, 73.2)" x="1219.87" y="73.2">HopperV2 Reward</text>
</g>
<polyline clip-path="url(#clip8402)" style="stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none" points="
  151.118,1479.74 161.859,1476.25 172.6,1415.17 183.341,1396.37 194.083,1410.37 204.824,1410.85 215.565,1410.51 226.306,1396.05 237.048,1356.61 247.789,1349.03 
  258.53,1266.32 269.272,1271.2 280.013,1196.31 290.754,1351.97 301.495,1352.95 312.237,1293.78 322.978,1342.42 333.719,1347.17 344.46,1348.77 355.202,1322.9 
  365.943,1340.82 376.684,1309.84 387.425,1313.14 398.167,1291.72 408.908,1197.09 419.649,1291.65 430.391,1300.99 441.132,1300.58 451.873,1298.23 462.614,1198.44 
  473.356,1097.64 484.097,993.174 494.838,1206.41 505.579,959.702 516.321,1130.5 527.062,1211.97 537.803,1248.12 548.545,1037.18 559.286,295.465 570.027,968.526 
  580.768,1068.46 591.51,1145.82 602.251,779.97 612.992,748.888 623.733,782.704 634.475,169.064 645.216,932.341 655.957,881.007 666.699,1069.18 677.44,407.016 
  688.181,436.025 698.922,799.506 709.664,831.944 720.405,994.16 731.146,908.565 741.887,482.646 752.629,675.885 763.37,405.195 774.111,380.734 784.853,489.558 
  795.594,259.39 806.335,739.174 817.076,937.666 827.818,447.531 838.559,426.033 849.3,403.371 860.041,495.497 870.783,509.261 881.524,514.165 892.265,485.011 
  903.007,474.997 913.748,459.789 924.489,488.826 935.23,430.325 945.972,306.342 956.713,378.7 967.454,372.788 978.195,412.356 988.937,346.629 999.678,397.33 
  1010.42,331.892 1021.16,567.779 1031.9,421.364 1042.64,403.872 1053.38,355.32 1064.13,370.44 1074.87,394.905 1085.61,399.973 1096.35,294.187 1107.09,349.342 
  1117.83,496.74 1128.57,336.456 1139.31,920.044 1150.06,823.775 1160.8,209.63 1171.54,239.606 1182.28,209.614 1193.02,227.882 1203.76,232.988 1214.5,351.994 
  1225.24,298.921 1235.99,260.728 1246.73,242.17 1257.47,226.661 1268.21,203.834 1278.95,211.848 1289.69,305.94 1300.43,353.181 1311.17,429.06 1321.92,407.155 
  1332.66,315.927 1343.4,270.484 1354.14,236.493 1364.88,288.246 1375.62,303.821 1386.36,357.454 1397.1,216.209 1407.85,271.045 1418.59,314.141 1429.33,213.697 
  1440.07,215.919 1450.81,187.213 1461.55,280.784 1472.29,164.671 1483.04,156.553 1493.78,676.696 1504.52,171.117 1515.26,260.412 1526,562.273 1536.74,848.708 
  1547.48,876.397 1558.22,980.941 1568.97,574.732 1579.71,899.784 1590.45,160.107 1601.19,807.349 1611.93,934.737 1622.67,148.388 1633.41,954.669 1644.15,693.819 
  1654.9,431.042 1665.64,821.001 1676.38,585.853 1687.12,165.18 1697.86,162.18 1708.6,126.852 1719.34,996.747 1730.08,355.779 1740.83,804.183 1751.57,817.817 
  1762.31,826.383 1773.05,683.894 1783.79,580.035 1794.53,225.552 1805.27,142.029 1816.01,769.778 1826.76,132.302 1837.5,108.526 1848.24,656.223 1858.98,120.617 
  1869.72,125.552 1880.46,618.217 1891.2,789.817 1901.94,870.718 1912.69,994.45 1923.43,561.913 1934.17,110.024 1944.91,321.182 1955.65,1115.14 1966.39,348.441 
  1977.13,807.845 1987.87,714.738 1998.62,529.323 2009.36,780.366 2020.1,760.9 2030.84,113.113 2041.58,662.32 2052.32,937.313 2063.06,845.503 2073.81,801.453 
  2084.55,872.797 2095.29,770.959 2106.03,866.527 2116.77,402.033 2127.51,812.501 2138.25,105.91 2148.99,752.346 2159.74,565.275 2170.48,198.801 2181.22,807.79 
  2191.96,750.563 2202.7,971.852 2213.44,863.856 2224.18,104.257 2234.92,749.766 2245.67,399.092 2256.41,550.512 2267.15,415.15 2277.89,295.811 2288.63,930.343 
  
  "/>
<polyline clip-path="url(#clip8402)" style="stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none" points="
  151.118,1479.17 161.859,1477.3 172.6,1467.53 183.341,1448.42 194.083,1415.78 204.824,1414.33 215.565,1409.11 226.306,1401.83 237.048,1389.52 247.789,1386.24 
  258.53,1376.18 269.272,1354.83 280.013,1353.34 290.754,1341.49 301.495,1343.9 312.237,1340.28 322.978,1312.75 333.719,1314.44 344.46,1309.11 355.202,1293.8 
  365.943,1271.75 376.684,1294.88 387.425,1286.82 398.167,1293.84 408.908,1269.16 419.649,1275.52 430.391,1289.77 441.132,1273.08 451.873,1253.25 462.614,1247.44 
  473.356,1224.9 484.097,1217.35 494.838,1226.22 505.579,1214.48 516.321,1204.43 527.062,1191.51 537.803,1190.71 548.545,1184.39 559.286,1173.85 570.027,1149.06 
  580.768,1146.06 591.51,1090.83 602.251,1115.56 612.992,1089.75 623.733,1144.92 634.475,1077.03 645.216,1049.65 655.957,999.54 666.699,1004.16 677.44,1082.17 
  688.181,1076.19 698.922,997.859 709.664,1063.04 720.405,1134.05 731.146,1131.75 741.887,1061.97 752.629,994.48 763.37,991.019 774.111,1099.8 784.853,1052.71 
  795.594,972.966 806.335,1007.63 817.076,1075.01 827.818,1011.67 838.559,983.418 849.3,976.093 860.041,770.994 870.783,852.009 881.524,868.86 892.265,896.094 
  903.007,920.169 913.748,828.469 924.489,901.748 935.23,843.484 945.972,929.506 956.713,908.11 967.454,932.439 978.195,897.852 988.937,961.671 999.678,884.051 
  1010.42,881.313 1021.16,995.159 1031.9,858.797 1042.64,830.031 1053.38,879.342 1064.13,941.931 1074.87,896.215 1085.61,804.39 1096.35,915.143 1107.09,834.086 
  1117.83,797.285 1128.57,877.988 1139.31,859.077 1150.06,856.034 1160.8,960.259 1171.54,999.127 1182.28,811.775 1193.02,847.69 1203.76,888.429 1214.5,818.135 
  1225.24,857.74 1235.99,950.974 1246.73,843.876 1257.47,873.26 1268.21,850.13 1278.95,785.166 1289.69,727.443 1300.43,838.809 1311.17,836.72 1321.92,844.59 
  1332.66,670.787 1343.4,676.341 1354.14,732.237 1364.88,812.607 1375.62,876.738 1386.36,661.963 1397.1,769.16 1407.85,693.163 1418.59,811.845 1429.33,840.207 
  1440.07,832.204 1450.81,656.873 1461.55,794.638 1472.29,805.101 1483.04,830.562 1493.78,715.395 1504.52,812.871 1515.26,710.765 1526,774.28 1536.74,804.149 
  1547.48,817.818 1558.22,705.812 1568.97,793.953 1579.71,666.565 1590.45,711.595 1601.19,725.775 1611.93,615.607 1622.67,764.762 1633.41,727.183 1644.15,761.142 
  1654.9,834.983 1665.64,609.104 1676.38,717.617 1687.12,428.49 1697.86,638.928 1708.6,703.325 1719.34,785.78 1730.08,745.617 1740.83,683.223 1751.57,762.968 
  1762.31,868.738 1773.05,808.404 1783.79,814.873 1794.53,778.875 1805.27,697.618 1816.01,503.265 1826.76,666.109 1837.5,615.636 1848.24,711.553 1858.98,728.958 
  1869.72,811.089 1880.46,692.245 1891.2,857.972 1901.94,703.969 1912.69,931.617 1923.43,977.173 1934.17,1107.25 1944.91,902.646 1955.65,917.652 1966.39,871.906 
  1977.13,980.223 1987.87,931.465 1998.62,922.843 2009.36,881.289 2020.1,808.537 2030.84,785.69 2041.58,819.333 2052.32,884.695 2063.06,719.363 2073.81,801.644 
  2084.55,814.785 2095.29,782.129 2106.03,639.415 2116.77,764.721 2127.51,641.756 2138.25,834.472 2148.99,813.146 2159.74,697.52 2170.48,849.773 2181.22,771.527 
  2191.96,886.106 2202.7,1002.23 2213.44,844.791 2224.18,764.986 2234.92,862.438 2245.67,709.909 2256.41,627.36 2267.15,669.689 2277.89,796.737 2288.63,888.587 
  
  "/>
<path clip-path="url(#clip8400)" d="
M1676.96 327.952 L2280.76 327.952 L2280.76 146.512 L1676.96 146.512  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<polyline clip-path="url(#clip8400)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1676.96,327.952 2280.76,327.952 2280.76,146.512 1676.96,146.512 1676.96,327.952 
  "/>
<polyline clip-path="url(#clip8400)" style="stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none" points="
  1700.96,206.992 1844.96,206.992 
  "/>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;" transform="rotate(0, 1868.96, 224.492)" x="1868.96" y="224.492">Mean Policy</text>
</g>
<polyline clip-path="url(#clip8400)" style="stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none" points="
  1700.96,267.472 1844.96,267.472 
  "/>
<g clip-path="url(#clip8400)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;" transform="rotate(0, 1868.96, 284.972)" x="1868.96" y="284.972">Stochastic Policy</text>
</g>
</svg>
<p>and save the logged results to the Experiment</p><pre><code class="language-julia">for (k, v) in get(lg)
    exper[k] = v
end
finish!(exper); # flushes everything to disk</code></pre><pre><code class="language-none">[ Info: Experiment saved to /tmp/hopper_example.jlso</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../MPPI/">« Running a simple controller</a><a class="docs-footer-nextpage" href="../visualize/">Visualizing Results »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 13 January 2020 04:26">Monday 13 January 2020</span>. Using Julia version 1.3.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
