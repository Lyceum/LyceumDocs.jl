<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Learning a control policy · Lyceum</title><link rel="canonical" href="https://docs.lyceum.ml/dev/examples/NPG/index.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Lyceum</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../MPPI/">Running a simple controller</a></li><li class="is-active"><a class="tocitem" href>Learning a control policy</a><ul class="internal"><li><a class="tocitem" href="#Policy-Gradient-Example-1"><span>Policy Gradient Example</span></a></li><li><a class="tocitem" href="#Policy-Gradient-Components-1"><span>Policy Gradient Components</span></a></li><li><a class="tocitem" href="#Running-Experiments-1"><span>Running Experiments</span></a></li></ul></li><li><a class="tocitem" href="../visualize/">Visualizing Results</a></li><li><a class="tocitem" href="../humanoid/">Creating a MuJoCo Environment</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Learning a control policy</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Learning a control policy</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/Lyceum/LyceumDocs.jl/blob/master/docs/src/examples/NPG.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><div class="admonition is-info"><header class="admonition-header">Running examples locally</header><div class="admonition-body"><p>This example and more are also available as Julia scripts and Jupyter notebooks.</p><p>See <a href="https://github.com/Lyceum/LyceumDocs.jl/blob/master/example_howto.md">the how-to page</a> for more information.</p></div></div><h1 id="Learning-a-control-policy-1"><a class="docs-heading-anchor" href="#Learning-a-control-policy-1">Learning a control policy</a><a class="docs-heading-anchor-permalink" href="#Learning-a-control-policy-1" title="Permalink"></a></h1><h2 id="Policy-Gradient-Example-1"><a class="docs-heading-anchor" href="#Policy-Gradient-Example-1">Policy Gradient Example</a><a class="docs-heading-anchor-permalink" href="#Policy-Gradient-Example-1" title="Permalink"></a></h2><p>In this example we walk through the process of setting up an experiment that runs <a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf">Natural Policy Gradient</a>, or more recently <a href="https://arxiv.org/abs/1703.02660">in this work</a>. This is an on-policy reinforcement learning method that is comparable to TRPO, PPO, and other policy gradient methods.</p><p>First, let&#39;s go head and grab all the dependencies</p><pre><code class="language-julia">using LinearAlgebra, Random, Statistics # From Stdlib
using LyceumAI         # For the NPG controller
using LyceumMuJoCo     # For the Hopper environment
using LyceumBase.Tools # For the ControllerIterator discussed below
using Flux             # For our Neural Network Needs
using Flux: glorot_uniform
using UniversalLogger
using Plots</code></pre><p>We first configure and instantiate of our <code>Hopper</code> environment to grab useful environment specific values such as the size of the observation and action vectors.</p><pre><code class="language-julia">env = LyceumMuJoCo.HopperV2();
dobs, dact = length(obsspace(env)), length(actionspace(env));</code></pre><h2 id="Policy-Gradient-Components-1"><a class="docs-heading-anchor" href="#Policy-Gradient-Components-1">Policy Gradient Components</a><a class="docs-heading-anchor-permalink" href="#Policy-Gradient-Components-1" title="Permalink"></a></h2><p>Policy Gradient methods require a policy: a function that takes in the state/observations of the agent, and output an action i.e. <code>action = π(obs)</code>. In much of Deep RL, the policy takes the form of a neural network which can be built on top of the <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> library. The network below is two layers, mapping from our observation space to 32 hidden units, to the second 32 hidden units layer, before emitting a vector of actions. The activations are all tanh functions, and we initialize the network with Glorot Uniform initializations. The policy is more than just a feed forward nerual network, however. It&#39;s treated as a stochastic variable, and thus we track the log of the standard deviation of noise to apply to the action sampling; this is final zero vector of size &#39;dact&#39;.</p><pre><code class="language-julia">policy = DiagGaussianPolicy(
    multilayer_perceptron(
        dobs,
        32,
        32,
        dact;
        σ = tanh,
        initb = glorot_uniform,
        initb_final = glorot_uniform,
    ),
    zeros(dact),
)</code></pre><pre><code class="language-none">LyceumAI.DiagGaussianPolicy{true,Flux.Chain{Tuple{Flux.Dense{typeof(tanh),Array{Float32,2},Array{Float32,1}},Flux.Dense{typeof(tanh),Array{Float32,2},Array{Float32,1}},Flux.Dense{typeof(identity),Array{Float32,2},Array{Float32,1}}}},Array{Float64,1}}(Chain(Dense(11, 32, tanh), Dense(32, 32, tanh), Dense(32, 3)), [0.0, 0.0, 0.0])</code></pre><p>Convert the weights of our policy to <code>Float32</code> rather than the default Float64 for performance.</p><pre><code class="language-julia">policy = Flux.paramtype(Float32, policy);</code></pre><p>This NPG implementation uses <a href="https://arxiv.org/pdf/1506.02438.pdf">Generalized Advantaged Estimation</a>, which requires an estimate of the value function <code>V(state)</code>, which we represent using a 2-layer, feedforward neural network.</p><pre><code class="language-julia">value = multilayer_perceptron(
    dobs,
    128,
    128,
    1;
    σ = Flux.relu,
    initb = glorot_uniform,
    initb_final = glorot_uniform,
)
value = Flux.paramtype(Float32, value);</code></pre><p>FluxTrainer is an iterator that loops on the Flux object provided. The result at each loop is passed to stopcb below, so you can quit after a number of epochs, convergence, or other criteria; here it&#39;s capped at two epochs as a lambda function.</p><pre><code class="language-julia">valueloss(bl, X, Y) = Flux.mse(vec(bl(X)), vec(Y))
valuetrainer = FluxTrainer(
    optimiser = ADAM(1e-3),
    szbatch = 64,
    lossfn = valueloss,
    stopcb = s -&gt; s.nepochs &gt; 2,
);</code></pre><p>The <code>NaturalPolicyGradient</code> iterator is a type that pre-allocates all necesary data structures and performs one gradient update to the policy at each iteration. We first pass in a constructor that given <code>n</code> returns <code>n</code> instances of <code>LyceumMuJoCo.HopperV2</code>, all sharing the same <code>jlModel</code>, to allow for performant sampling from our policy. We then pass in the <code>policy</code>, <code>value</code>, and <code>valuetrainer</code> instances constructed above and override a few of the default <code>NaturalPolicyGradient</code> parameters: <code>gamma</code>, <code>gaelambda</code>, and <code>norm_step_size</code>. Finally, we set the max trajectory length <code>Hmax</code> and total number of samples per iteration, <code>N</code>. Under the hood, <code>NaturalPolicyGradient</code> will use approximately <code>div(N, Hmax)</code> threads to perform the sampling.</p><pre><code class="language-julia">npg = NaturalPolicyGradient(
    n -&gt; tconstruct(LyceumMuJoCo.HopperV2, n),
    policy,
    value,
    valuetrainer;
    gamma = 0.995,
    gaelambda = 0.97,
    norm_step_size = 0.05,
    Hmax = 1000,
    N = 10000,
);</code></pre><h2 id="Running-Experiments-1"><a class="docs-heading-anchor" href="#Running-Experiments-1">Running Experiments</a><a class="docs-heading-anchor-permalink" href="#Running-Experiments-1" title="Permalink"></a></h2><p>Finally, let&#39;s spin on our iterator 200 times, plotting every 20 iterations. This lets us break out of the loop if certain conditions are met, or re-start training manually if needed. We of course wish to track results, so we create an <code>Experiment</code> to which we can save data. We also have useful timing information displayed every 20 iterations to understand CPU performance.</p><pre><code class="language-julia">exper = Experiment(&quot;/tmp/hopper_example.jlso&quot;, overwrite = true)
lg = ULogger() # walks, talks, and acts like a Julia logger. See the docs on UniversalLogger for more info.
for (i, state) in enumerate(npg)
    if i &gt; 200
        # serialize some stuff and quit
        exper[:policy] = npg.policy
        exper[:value] = npg.value
        exper[:etype] = LyceumMuJoCo.HopperV2
        exper[:meanstates] = state.meanbatch
        exper[:stocstates] = state.stocbatch
        break
    end

    # log everything in `state` except meanbatch and stocbatch
    push!(lg, :algstate, filter_nt(state, exclude = (:meanbatch, :stocbatch)))

    if mod(i, 20) == 0
        x = lg[:algstate]
        # The following are helper functions for plotting to the terminal.
        # The first plot displays the eval function for our stochastic
        # and mean policy rollouts.
        display(expplot(
            Line(x[:stocterminal_eval], &quot;StocLastE&quot;),
            Line(x[:meanterminal_eval], &quot;MeanLastE&quot;),
            title = &quot;Evaluation Score, Iter=$i&quot;,
            width = 60,
            height = 8,
        ))
        # While the second one similarly plots the reward.
        display(expplot(
            Line(x[:stoctraj_reward], &quot;StocR&quot;),
            Line(x[:meantraj_reward], &quot;MeanR&quot;),
            title = &quot;Reward, Iter=$i&quot;,
            width = 60,
            height = 8,
        ))

        # The following are timing values for various parts of the Natural Policy Gradient
        # algorithm at the last iteration, useful for finding performance bottlenecks in the algorithm.
        println(&quot;elapsed_sampled  = &quot;, state.elapsed_sampled)
        println(&quot;elapsed_gradll   = &quot;, state.elapsed_gradll)
        println(&quot;elapsed_vpg      = &quot;, state.elapsed_vpg)
        println(&quot;elapsed_cg       = &quot;, state.elapsed_cg)
        println(&quot;elapsed_valuefit = &quot;, state.elapsed_valuefit)
    end
end</code></pre><pre><code class="language-none">┌ Warning: The specified values for size and/or count will result in 16 unused data points
└ @ MLDataPattern ~/.julia/packages/MLDataPattern/mX21p/src/dataview.jl:204
elapsed_sampled  = 0.389237077
elapsed_gradll   = 1.422417528
elapsed_vpg      = 0.004608937
elapsed_cg       = 0.079744096
elapsed_valuefit = 1.02319741
elapsed_sampled  = 0.35064258
elapsed_gradll   = 1.417585467
elapsed_vpg      = 0.008872813
elapsed_cg       = 0.082384336
elapsed_valuefit = 0.918995604
elapsed_sampled  = 0.344146899
elapsed_gradll   = 1.424613251
elapsed_vpg      = 0.004276384
elapsed_cg       = 0.08253614
elapsed_valuefit = 0.916721406
elapsed_sampled  = 0.354259534
elapsed_gradll   = 1.392007529
elapsed_vpg      = 0.004391376
elapsed_cg       = 0.080915043
elapsed_valuefit = 0.947762158
elapsed_sampled  = 0.365807774
elapsed_gradll   = 1.440858963
elapsed_vpg      = 0.004585574
elapsed_cg       = 0.079634914
elapsed_valuefit = 1.015772105
elapsed_sampled  = 0.358791575
elapsed_gradll   = 1.386616595
elapsed_vpg      = 0.004023045
elapsed_cg       = 0.082446378
elapsed_valuefit = 0.892407766
elapsed_sampled  = 0.350007993
elapsed_gradll   = 1.425393307
elapsed_vpg      = 0.004654861
elapsed_cg       = 0.079535767
elapsed_valuefit = 0.955739582
elapsed_sampled  = 0.375137968
elapsed_gradll   = 1.393728517
elapsed_vpg      = 0.004111539
elapsed_cg       = 0.081616452
elapsed_valuefit = 1.057205084
elapsed_sampled  = 0.342618472
elapsed_gradll   = 1.379750766
elapsed_vpg      = 0.004434045
elapsed_cg       = 0.080780055
elapsed_valuefit = 1.19264563
elapsed_sampled  = 0.377092349
elapsed_gradll   = 1.375441287
elapsed_vpg      = 0.004521146
elapsed_cg       = 0.087360712
elapsed_valuefit = 1.258396335</code></pre><p>Let&#39;s go ahead and plot the final reward trajectory for our stochastic and mean policies to see how we did.</p><pre><code class="language-julia">plot!(
    plot(lg[:algstate][:meantraj_reward], label = &quot;Mean Policy&quot;, title = &quot;HopperV2 Reward&quot;),
    lg[:algstate][:stoctraj_reward],
    label = &quot;Stochastic Policy&quot;,
)</code></pre><?xml version="1.0" encoding="utf-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600">
<defs>
  <clipPath id="clip8200">
    <rect x="0" y="0" width="2400" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip8200)" d="
M0 1600 L2400 1600 L2400 0 L0 0  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip8201">
    <rect x="480" y="0" width="1681" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip8200)" d="
M86.9921 1521.01 L2352.76 1521.01 L2352.76 62.9921 L86.9921 62.9921  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip8202">
    <rect x="86" y="62" width="2267" height="1459"/>
  </clipPath>
</defs>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  140.376,1521.01 140.376,62.9921 
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  677.44,1521.01 677.44,62.9921 
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1214.5,1521.01 1214.5,62.9921 
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1751.57,1521.01 1751.57,62.9921 
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2288.63,1521.01 2288.63,62.9921 
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,1481.77 2352.76,1481.77 
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,1026.61 2352.76,1026.61 
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,571.454 2352.76,571.454 
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,116.298 2352.76,116.298 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1521.01 2352.76,1521.01 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1521.01 86.9921,62.9921 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  140.376,1521.01 140.376,1503.51 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  677.44,1521.01 677.44,1503.51 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1214.5,1521.01 1214.5,1503.51 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1751.57,1521.01 1751.57,1503.51 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  2288.63,1521.01 2288.63,1503.51 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1481.77 114.181,1481.77 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1026.61 114.181,1026.61 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,571.454 114.181,571.454 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,116.298 114.181,116.298 
  "/>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 140.376, 1575.01)" x="140.376" y="1575.01">0</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 677.44, 1575.01)" x="677.44" y="1575.01">50</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 1214.5, 1575.01)" x="1214.5" y="1575.01">100</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 1751.57, 1575.01)" x="1751.57" y="1575.01">150</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 2288.63, 1575.01)" x="2288.63" y="1575.01">200</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 1499.27)" x="62.9921" y="1499.27">0</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 1044.11)" x="62.9921" y="1044.11">1000</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 588.954)" x="62.9921" y="588.954">2000</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 133.798)" x="62.9921" y="133.798">3000</text>
</g>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;" transform="rotate(0, 1219.87, 73.2)" x="1219.87" y="73.2">HopperV2 Reward</text>
</g>
<polyline clip-path="url(#clip8202)" style="stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none" points="
  151.118,1479.74 161.859,1479.59 172.6,1479.26 183.341,1479.06 194.083,1478.43 204.824,1446.36 215.565,1458.68 226.306,1458.85 237.048,1456.84 247.789,1379.36 
  258.53,1415.83 269.272,1393.34 280.013,1381.42 290.754,1357.39 301.495,1354.85 312.237,1202.65 322.978,1323.9 333.719,1214.61 344.46,1320.81 355.202,1329.73 
  365.943,1346.35 376.684,1316.26 387.425,1102.38 398.167,1052.1 408.908,1094.3 419.649,868.959 430.391,1320.06 441.132,1318.05 451.873,1318.52 462.614,1324.53 
  473.356,1321.01 484.097,720.463 494.838,1323.51 505.579,1204.28 516.321,1021.9 527.062,405.632 537.803,411.447 548.545,466.203 559.286,524.401 570.027,1170 
  580.768,495.587 591.51,327.493 602.251,393.283 612.992,392.726 623.733,428.074 634.475,376.893 645.216,376.277 655.957,357.105 666.699,342.4 677.44,412.211 
  688.181,385.385 698.922,417.78 709.664,403.124 720.405,367.023 731.146,354.123 741.887,329.587 752.629,339.351 763.37,326.506 774.111,339.113 784.853,371.964 
  795.594,351.823 806.335,325.624 817.076,274.765 827.818,252.638 838.559,236.858 849.3,208.668 860.041,176.899 870.783,195.401 881.524,178.676 892.265,162.884 
  903.007,250.724 913.748,210.66 924.489,1415.42 935.23,167.251 945.972,175.638 956.713,156.023 967.454,237.654 978.195,253.459 988.937,224.513 999.678,164.648 
  1010.42,161.945 1021.16,189.931 1031.9,223.093 1042.64,245.922 1053.38,186.475 1064.13,177.063 1074.87,216.238 1085.61,283.815 1096.35,202.279 1107.09,208.762 
  1117.83,246.894 1128.57,307.177 1139.31,240.877 1150.06,267.865 1160.8,311.36 1171.54,256.6 1182.28,297.751 1193.02,231.672 1203.76,266.357 1214.5,227.72 
  1225.24,204.031 1235.99,206.581 1246.73,179.422 1257.47,238.189 1268.21,268.115 1278.95,248.84 1289.69,279.198 1300.43,295.194 1311.17,315.902 1321.92,259.695 
  1332.66,171.938 1343.4,280.477 1354.14,243.136 1364.88,163.956 1375.62,153.133 1386.36,164.965 1397.1,313.665 1407.85,317.11 1418.59,207.545 1429.33,183.417 
  1440.07,153.246 1450.81,169.797 1461.55,200.313 1472.29,234.338 1483.04,323.381 1493.78,329.692 1504.52,264.675 1515.26,200.603 1526,246.411 1536.74,316.078 
  1547.48,273.824 1558.22,302.337 1568.97,295.135 1579.71,232.183 1590.45,220.561 1601.19,224.664 1611.93,216.248 1622.67,237.516 1633.41,211.381 1644.15,198.901 
  1654.9,209.375 1665.64,203.722 1676.38,258.111 1687.12,208.704 1697.86,219.908 1708.6,197.901 1719.34,184.942 1730.08,198.254 1740.83,193.266 1751.57,197.901 
  1762.31,176.84 1773.05,193.444 1783.79,201.671 1794.53,170.523 1805.27,177.21 1816.01,180.836 1826.76,182.908 1837.5,207.116 1848.24,169.82 1858.98,154.339 
  1869.72,163.496 1880.46,162.518 1891.2,137.468 1901.94,126.739 1912.69,130.313 1923.43,124.54 1934.17,129.602 1944.91,104.257 1955.65,137.314 1966.39,109.586 
  1977.13,105.128 1987.87,118.375 1998.62,120.575 2009.36,143.268 2020.1,122.096 2030.84,105.245 2041.58,153.922 2052.32,162.563 2063.06,146.009 2073.81,163.225 
  2084.55,129.858 2095.29,132.121 2106.03,139.537 2116.77,137.929 2127.51,121.125 2138.25,144.892 2148.99,161.523 2159.74,171.806 2170.48,176.96 2181.22,186.38 
  2191.96,159.129 2202.7,137.852 2213.44,129.327 2224.18,121.928 2234.92,163.967 2245.67,155.088 2256.41,175.702 2267.15,178.86 2277.89,156.132 2288.63,144.846 
  
  "/>
<polyline clip-path="url(#clip8202)" style="stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none" points="
  151.118,1479.2 161.859,1478.99 172.6,1478.67 183.341,1477.92 194.083,1475.51 204.824,1468.53 215.565,1459.35 226.306,1453.12 237.048,1446.13 247.789,1429.24 
  258.53,1423.64 269.272,1406.58 280.013,1390.08 290.754,1390.08 301.495,1376.78 312.237,1372.44 322.978,1368.61 333.719,1360.35 344.46,1353.23 355.202,1338.28 
  365.943,1335.36 376.684,1317.68 387.425,1296.72 398.167,1265.36 408.908,1240.39 419.649,1231.09 430.391,1204.06 441.132,1174.18 451.873,1169.39 462.614,1168.51 
  473.356,1105.44 484.097,1165.2 494.838,1104.73 505.579,1092.48 516.321,1008.52 527.062,1002.94 537.803,1032.38 548.545,1110.09 559.286,1078.15 570.027,1006.53 
  580.768,808.959 591.51,829.493 602.251,657.353 612.992,720.119 623.733,574.31 634.475,831.824 645.216,618.313 655.957,693.74 666.699,700.653 677.44,787.222 
  688.181,500.681 698.922,695.354 709.664,694.439 720.405,609.62 731.146,601.733 741.887,647.852 752.629,977.478 763.37,776.369 774.111,502.127 784.853,783.537 
  795.594,747.097 806.335,715.832 817.076,721.344 827.818,482.522 838.559,682.193 849.3,483.594 860.041,595.003 870.783,455.183 881.524,711.364 892.265,539.465 
  903.007,421.795 913.748,565.147 924.489,962.22 935.23,652.595 945.972,458.372 956.713,528.537 967.454,637.29 978.195,672.396 988.937,666.572 999.678,868.845 
  1010.42,686.327 1021.16,378.257 1031.9,575.023 1042.64,826.859 1053.38,805.136 1064.13,641.879 1074.87,348.695 1085.61,379.367 1096.35,379.967 1107.09,398.029 
  1117.83,288.924 1128.57,301.478 1139.31,477.935 1150.06,295.386 1160.8,195.142 1171.54,580.814 1182.28,185.355 1193.02,420.513 1203.76,546.752 1214.5,265.408 
  1225.24,359.192 1235.99,278.729 1246.73,267.702 1257.47,240.34 1268.21,261.442 1278.95,262.607 1289.69,483.598 1300.43,350.399 1311.17,660.449 1321.92,918.897 
  1332.66,911.537 1343.4,583.854 1354.14,1079.6 1364.88,877.572 1375.62,773.056 1386.36,338.828 1397.1,521.547 1407.85,660.522 1418.59,533.084 1429.33,515.77 
  1440.07,271.808 1450.81,161.227 1461.55,279.092 1472.29,167.916 1483.04,278.398 1493.78,308.988 1504.52,500.058 1515.26,205.399 1526,328.717 1536.74,336.062 
  1547.48,317.888 1558.22,209.529 1568.97,313.4 1579.71,307.608 1590.45,301.453 1601.19,300.361 1611.93,296.051 1622.67,393.482 1633.41,283.386 1644.15,473.214 
  1654.9,476.866 1665.64,552.386 1676.38,301.96 1687.12,479.728 1697.86,390.143 1708.6,475.462 1719.34,392.574 1730.08,387.347 1740.83,288.7 1751.57,282.536 
  1762.31,165.48 1773.05,401.442 1783.79,185.342 1794.53,164.303 1805.27,171.589 1816.01,257.565 1826.76,365.345 1837.5,362.003 1848.24,238.323 1858.98,374.002 
  1869.72,275.137 1880.46,263.368 1891.2,249.752 1901.94,347.089 1912.69,510.905 1923.43,325.388 1934.17,234.699 1944.91,322.262 1955.65,259.773 1966.39,481.926 
  1977.13,317.934 1987.87,314.591 1998.62,335.562 2009.36,250.203 2020.1,428.965 2030.84,623.404 2041.58,380.187 2052.32,262.191 2063.06,137.452 2073.81,281.365 
  2084.55,354.426 2095.29,351.256 2106.03,352.74 2116.77,449.108 2127.51,422.88 2138.25,515.126 2148.99,364.086 2159.74,256.421 2170.48,439.13 2181.22,155.47 
  2191.96,233.416 2202.7,478.977 2213.44,306.076 2224.18,316.268 2234.92,261.974 2245.67,253.105 2256.41,161.718 2267.15,152.516 2277.89,147.203 2288.63,358.37 
  
  "/>
<path clip-path="url(#clip8200)" d="
M1676.96 327.952 L2280.76 327.952 L2280.76 146.512 L1676.96 146.512  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<polyline clip-path="url(#clip8200)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1676.96,327.952 2280.76,327.952 2280.76,146.512 1676.96,146.512 1676.96,327.952 
  "/>
<polyline clip-path="url(#clip8200)" style="stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none" points="
  1700.96,206.992 1844.96,206.992 
  "/>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;" transform="rotate(0, 1868.96, 224.492)" x="1868.96" y="224.492">Mean Policy</text>
</g>
<polyline clip-path="url(#clip8200)" style="stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none" points="
  1700.96,267.472 1844.96,267.472 
  "/>
<g clip-path="url(#clip8200)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;" transform="rotate(0, 1868.96, 284.972)" x="1868.96" y="284.972">Stochastic Policy</text>
</g>
</svg>
<p>and save the logged results to the Experiment</p><pre><code class="language-julia">for (k, v) in get(lg)
    exper[k] = v
end
finish!(exper); # flushes everything to disk</code></pre><pre><code class="language-none">[ Info: Experiment saved to /tmp/hopper_example.jlso</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../MPPI/">« Running a simple controller</a><a class="docs-footer-nextpage" href="../visualize/">Visualizing Results »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 13 January 2020 07:40">Monday 13 January 2020</span>. Using Julia version 1.3.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
