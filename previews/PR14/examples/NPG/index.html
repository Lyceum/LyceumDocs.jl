<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Learning a control policy · Lyceum</title><link rel="canonical" href="https://docs.lyceum.ml/dev/examples/NPG/index.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Lyceum</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../MPPI/">Running a simple controller</a></li><li class="is-active"><a class="tocitem" href>Learning a control policy</a><ul class="internal"><li><a class="tocitem" href="#Policy-Gradient-Example-1"><span>Policy Gradient Example</span></a></li><li><a class="tocitem" href="#Policy-Gradient-Components-1"><span>Policy Gradient Components</span></a></li><li><a class="tocitem" href="#Running-Experiments-1"><span>Running Experiments</span></a></li></ul></li><li><a class="tocitem" href="../visualize/">Visualizing Results</a></li><li><a class="tocitem" href="../humanoid/">Creating a MuJoCo Environment</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Learning a control policy</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Learning a control policy</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/Lyceum/LyceumDocs.jl/blob/master/docs/src/examples/NPG.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><div class="admonition is-info"><header class="admonition-header">Running examples locally</header><div class="admonition-body"><p>This example and more are also available as Julia scripts and Jupyter notebooks.</p><p>See <a href="https://github.com/Lyceum/LyceumDocs.jl/blob/master/example_howto.md">the how-to page</a> for more information.</p></div></div><h1 id="Learning-a-control-policy-1"><a class="docs-heading-anchor" href="#Learning-a-control-policy-1">Learning a control policy</a><a class="docs-heading-anchor-permalink" href="#Learning-a-control-policy-1" title="Permalink"></a></h1><h2 id="Policy-Gradient-Example-1"><a class="docs-heading-anchor" href="#Policy-Gradient-Example-1">Policy Gradient Example</a><a class="docs-heading-anchor-permalink" href="#Policy-Gradient-Example-1" title="Permalink"></a></h2><p>In this example we walk through the process of setting up an experiment that runs <a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf">Natural Policy Gradient</a>, or more recently <a href="https://arxiv.org/abs/1703.02660">in this work</a>. This is an on-policy reinforcement learning method that is comparable to TRPO, PPO, and other policy gradient methods.</p><p>First, let&#39;s go head and grab all the dependencies</p><pre><code class="language-julia">using LinearAlgebra, Random, Statistics # From Stdlib
using LyceumAI         # For the NPG controller
using LyceumMuJoCo     # For the Hopper environment
using LyceumBase.Tools # For the ControllerIterator discussed below
using Flux             # For our Neural Network Needs
using Flux: glorot_uniform
using UniversalLogger
using Plots</code></pre><p>We first configure and instantiate of our <code>Hopper</code> environment to grab useful environment specific values such as the size of the observation and action vectors.</p><pre><code class="language-julia">env = LyceumMuJoCo.HopperV2();
dobs, dact = length(obsspace(env)), length(actionspace(env));</code></pre><h2 id="Policy-Gradient-Components-1"><a class="docs-heading-anchor" href="#Policy-Gradient-Components-1">Policy Gradient Components</a><a class="docs-heading-anchor-permalink" href="#Policy-Gradient-Components-1" title="Permalink"></a></h2><p>Policy Gradient methods require a policy: a function that takes in the state/observations of the agent, and output an action i.e. <code>action = π(obs)</code>. In much of Deep RL, the policy takes the form of a neural network which can be built on top of the <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> library. The network below is two layers, mapping from our observation space to 32 hidden units, to the second 32 hidden units layer, before emitting a vector of actions. The activations are all tanh functions, and we initialize the network with Glorot Uniform initializations. The policy is more than just a feed forward nerual network, however. It&#39;s treated as a stochastic variable, and thus we track the log of the standard deviation of noise to apply to the action sampling; this is final zero vector of size &#39;dact&#39;.</p><pre><code class="language-julia">policy = DiagGaussianPolicy(
    multilayer_perceptron(
        dobs,
        32,
        32,
        dact;
        σ = tanh,
        initb = glorot_uniform,
        initb_final = glorot_uniform,
    ),
    zeros(dact),
)</code></pre><pre><code class="language-none">LyceumAI.DiagGaussianPolicy{true,Flux.Chain{Tuple{Flux.Dense{typeof(tanh),Array{Float32,2},Array{Float32,1}},Flux.Dense{typeof(tanh),Array{Float32,2},Array{Float32,1}},Flux.Dense{typeof(identity),Array{Float32,2},Array{Float32,1}}}},Array{Float64,1}}(Chain(Dense(11, 32, tanh), Dense(32, 32, tanh), Dense(32, 3)), [0.0, 0.0, 0.0])</code></pre><p>Convert the weights of our policy to <code>Float32</code> rather than the default Float64 for performance.</p><pre><code class="language-julia">policy = Flux.paramtype(Float32, policy);</code></pre><p>This NPG implementation uses <a href="https://arxiv.org/pdf/1506.02438.pdf">Generalized Advantaged Estimation</a>, which requires an estimate of the value function <code>V(state)</code>, which we represent using a 2-layer, feedforward neural network.</p><pre><code class="language-julia">value = multilayer_perceptron(
    dobs,
    128,
    128,
    1;
    σ = Flux.relu,
    initb = glorot_uniform,
    initb_final = glorot_uniform,
)
value = Flux.paramtype(Float32, value);</code></pre><p>FluxTrainer is an iterator that loops on the Flux object provided. The result at each loop is passed to stopcb below, so you can quit after a number of epochs, convergence, or other criteria; here it&#39;s capped at two epochs as a lambda function.</p><pre><code class="language-julia">valueloss(bl, X, Y) = Flux.mse(vec(bl(X)), vec(Y))
valuetrainer = FluxTrainer(
    optimiser = ADAM(1e-3),
    szbatch = 64,
    lossfn = valueloss,
    stopcb = s -&gt; s.nepochs &gt; 2,
);</code></pre><p>The <code>NaturalPolicyGradient</code> iterator is a type that pre-allocates all necesary data structures and performs one gradient update to the policy at each iteration. We first pass in a constructor that given <code>n</code> returns <code>n</code> instances of <code>LyceumMuJoCo.HopperV2</code>, all sharing the same <code>jlModel</code>, to allow for performant sampling from our policy. We then pass in the <code>policy</code>, <code>value</code>, and <code>valuetrainer</code> instances constructed above and override a few of the default <code>NaturalPolicyGradient</code> parameters: <code>gamma</code>, <code>gaelambda</code>, and <code>norm_step_size</code>. Finally, we set the max trajectory length <code>Hmax</code> and total number of samples per iteration, <code>N</code>. Under the hood, <code>NaturalPolicyGradient</code> will use approximately <code>div(N, Hmax)</code> threads to perform the sampling.</p><pre><code class="language-julia">npg = NaturalPolicyGradient(
    n -&gt; tconstruct(LyceumMuJoCo.HopperV2, n),
    policy,
    value,
    valuetrainer;
    gamma = 0.995,
    gaelambda = 0.97,
    norm_step_size = 0.05,
    Hmax = 1000,
    N = 10000,
);</code></pre><h2 id="Running-Experiments-1"><a class="docs-heading-anchor" href="#Running-Experiments-1">Running Experiments</a><a class="docs-heading-anchor-permalink" href="#Running-Experiments-1" title="Permalink"></a></h2><p>Finally, let&#39;s spin on our iterator 200 times, plotting every 20 iterations. This lets us break out of the loop if certain conditions are met, or re-start training manually if needed. We of course wish to track results, so we create an <code>Experiment</code> to which we can save data. We also have useful timing information displayed every 20 iterations to understand CPU performance.</p><pre><code class="language-julia">exper = Experiment(&quot;/tmp/hopper_example.jlso&quot;, overwrite = true)
lg = ULogger() # walks, talks, and acts like a Julia logger. See the docs on UniversalLogger for more info.
for (i, state) in enumerate(npg)
    if i &gt; 200
        # serialize some stuff and quit
        exper[:policy] = npg.policy
        exper[:value] = npg.value
        exper[:etype] = LyceumMuJoCo.HopperV2
        exper[:meanstates] = state.meanbatch
        exper[:stocstates] = state.stocbatch
        break
    end

    # log everything in `state` except meanbatch and stocbatch
    push!(lg, :algstate, filter_nt(state, exclude = (:meanbatch, :stocbatch)))

    if mod(i, 20) == 0
        x = lg[:algstate]
        # The following are helper functions for plotting to the terminal.
        # The first plot displays the eval function for our stochastic
        # and mean policy rollouts.
        display(expplot(
            Line(x[:stocterminal_eval], &quot;StocLastE&quot;),
            Line(x[:meanterminal_eval], &quot;MeanLastE&quot;),
            title = &quot;Evaluation Score, Iter=$i&quot;,
            width = 60,
            height = 8,
        ))
        # While the second one similarly plots the reward.
        display(expplot(
            Line(x[:stoctraj_reward], &quot;StocR&quot;),
            Line(x[:meantraj_reward], &quot;MeanR&quot;),
            title = &quot;Reward, Iter=$i&quot;,
            width = 60,
            height = 8,
        ))

        # The following are timing values for various parts of the Natural Policy Gradient
        # algorithm at the last iteration, useful for finding performance bottlenecks in the algorithm.
        println(&quot;elapsed_sampled  = &quot;, state.elapsed_sampled)
        println(&quot;elapsed_gradll   = &quot;, state.elapsed_gradll)
        println(&quot;elapsed_vpg      = &quot;, state.elapsed_vpg)
        println(&quot;elapsed_cg       = &quot;, state.elapsed_cg)
        println(&quot;elapsed_valuefit = &quot;, state.elapsed_valuefit)
    end
end</code></pre><pre><code class="language-none">┌ Warning: The specified values for size and/or count will result in 16 unused data points
└ @ MLDataPattern ~/.julia/packages/MLDataPattern/mX21p/src/dataview.jl:204
elapsed_sampled  = 0.322071173
elapsed_gradll   = 1.374259629
elapsed_vpg      = 0.004643312
elapsed_cg       = 0.080298067
elapsed_valuefit = 0.953828011
elapsed_sampled  = 0.313732018
elapsed_gradll   = 1.353525707
elapsed_vpg      = 0.004265073
elapsed_cg       = 0.08831909
elapsed_valuefit = 0.975150882
elapsed_sampled  = 0.33658393
elapsed_gradll   = 1.311928501
elapsed_vpg      = 0.00515769
elapsed_cg       = 0.081865211
elapsed_valuefit = 0.935693513
elapsed_sampled  = 0.335723971
elapsed_gradll   = 1.311931247
elapsed_vpg      = 0.005077271
elapsed_cg       = 0.090012141
elapsed_valuefit = 0.95240104
elapsed_sampled  = 0.346164693
elapsed_gradll   = 1.288679876
elapsed_vpg      = 0.004678647
elapsed_cg       = 0.079792505
elapsed_valuefit = 1.092923871
elapsed_sampled  = 0.327685489
elapsed_gradll   = 1.298924532
elapsed_vpg      = 0.004442431
elapsed_cg       = 0.085142911
elapsed_valuefit = 0.968791321
elapsed_sampled  = 0.326378861
elapsed_gradll   = 1.328165534
elapsed_vpg      = 0.004228519
elapsed_cg       = 0.102405969
elapsed_valuefit = 1.041394521
elapsed_sampled  = 0.351922463
elapsed_gradll   = 1.316927167
elapsed_vpg      = 0.004580023
elapsed_cg       = 0.07974344
elapsed_valuefit = 1.125740456
elapsed_sampled  = 0.348357629
elapsed_gradll   = 1.319308356
elapsed_vpg      = 0.005135833
elapsed_cg       = 0.080951295
elapsed_valuefit = 1.325260131
elapsed_sampled  = 0.368488866
elapsed_gradll   = 1.350588834
elapsed_vpg      = 0.004732719
elapsed_cg       = 0.08159275
elapsed_valuefit = 1.370966765</code></pre><p>Let&#39;s go ahead and plot the final reward trajectory for our stochastic and mean policies to see how we did.</p><pre><code class="language-julia">plot!(
    plot(lg[:algstate][:meantraj_reward], label = &quot;Mean Policy&quot;, title = &quot;HopperV2 Reward&quot;),
    lg[:algstate][:stoctraj_reward],
    label = &quot;Stochastic Policy&quot;,
)</code></pre><?xml version="1.0" encoding="utf-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600">
<defs>
  <clipPath id="clip9900">
    <rect x="0" y="0" width="2400" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip9900)" d="
M0 1600 L2400 1600 L2400 0 L0 0  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip9901">
    <rect x="480" y="0" width="1681" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip9900)" d="
M86.9921 1521.01 L2352.76 1521.01 L2352.76 62.9921 L86.9921 62.9921  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip9902">
    <rect x="86" y="62" width="2267" height="1459"/>
  </clipPath>
</defs>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  140.376,1521.01 140.376,62.9921 
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  677.44,1521.01 677.44,62.9921 
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1214.5,1521.01 1214.5,62.9921 
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1751.57,1521.01 1751.57,62.9921 
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2288.63,1521.01 2288.63,62.9921 
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,1482.24 2352.76,1482.24 
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,1020.37 2352.76,1020.37 
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,558.51 2352.76,558.51 
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  86.9921,96.6458 2352.76,96.6458 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1521.01 2352.76,1521.01 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1521.01 86.9921,62.9921 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  140.376,1521.01 140.376,1503.51 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  677.44,1521.01 677.44,1503.51 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1214.5,1521.01 1214.5,1503.51 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1751.57,1521.01 1751.57,1503.51 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  2288.63,1521.01 2288.63,1503.51 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1482.24 114.181,1482.24 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,1020.37 114.181,1020.37 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,558.51 114.181,558.51 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  86.9921,96.6458 114.181,96.6458 
  "/>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 140.376, 1575.01)" x="140.376" y="1575.01">0</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 677.44, 1575.01)" x="677.44" y="1575.01">50</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 1214.5, 1575.01)" x="1214.5" y="1575.01">100</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 1751.57, 1575.01)" x="1751.57" y="1575.01">150</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;" transform="rotate(0, 2288.63, 1575.01)" x="2288.63" y="1575.01">200</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 1499.74)" x="62.9921" y="1499.74">0</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 1037.87)" x="62.9921" y="1037.87">1000</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 576.01)" x="62.9921" y="576.01">2000</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;" transform="rotate(0, 62.9921, 114.146)" x="62.9921" y="114.146">3000</text>
</g>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;" transform="rotate(0, 1219.87, 73.2)" x="1219.87" y="73.2">HopperV2 Reward</text>
</g>
<polyline clip-path="url(#clip9902)" style="stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none" points="
  151.118,1479.74 161.859,1479.54 172.6,1478.41 183.341,1452.01 194.083,1455.34 204.824,1453.27 215.565,1449.91 226.306,1384.33 237.048,1385.32 247.789,1382.84 
  258.53,1380.51 269.272,1379.62 280.013,1350.15 290.754,1341.3 301.495,1337.34 312.237,1335.44 322.978,1315.35 333.719,1318.5 344.46,1300.09 355.202,1181.47 
  365.943,1179.19 376.684,1175.41 387.425,1151.78 398.167,1180.13 408.908,1130.68 419.649,1204.83 430.391,1229.82 441.132,1290.89 451.873,1296.85 462.614,1165.45 
  473.356,1156.88 484.097,1020.73 494.838,949.531 505.579,814.504 516.321,1344.1 527.062,1338.4 537.803,890.073 548.545,541.295 559.286,507.431 570.027,622.342 
  580.768,484.098 591.51,619.738 602.251,557.711 612.992,563.12 623.733,671.365 634.475,471.163 645.216,456.323 655.957,506.654 666.699,506.875 677.44,538.929 
  688.181,521.461 698.922,518.569 709.664,527.231 720.405,489.927 731.146,480.971 741.887,461.819 752.629,422.095 763.37,361.774 774.111,410.504 784.853,465.385 
  795.594,471.696 806.335,458.933 817.076,446.466 827.818,409.442 838.559,775.999 849.3,968.826 860.041,393.149 870.783,417.944 881.524,418.399 892.265,404.063 
  903.007,332.403 913.748,234.279 924.489,179.636 935.23,408.222 945.972,423.988 956.713,413.298 967.454,333.373 978.195,387.678 988.937,341.146 999.678,405.229 
  1010.42,425.096 1021.16,386.159 1031.9,376.325 1042.64,201.159 1053.38,158.152 1064.13,147.078 1074.87,215.64 1085.61,270.228 1096.35,237.704 1107.09,206.778 
  1117.83,257.223 1128.57,251.771 1139.31,138.066 1150.06,152.496 1160.8,228.644 1171.54,216.84 1182.28,212.662 1193.02,260.131 1203.76,244.048 1214.5,215.938 
  1225.24,178.529 1235.99,150.722 1246.73,209.598 1257.47,249.622 1268.21,238.297 1278.95,177.073 1289.69,116.785 1300.43,104.257 1311.17,223.532 1321.92,218.123 
  1332.66,251.7 1343.4,257.129 1354.14,197.57 1364.88,150.081 1375.62,181.162 1386.36,193.849 1397.1,117.891 1407.85,266.546 1418.59,275.112 1429.33,164.491 
  1440.07,172.17 1450.81,187.797 1461.55,162.65 1472.29,151.034 1483.04,199.54 1493.78,112.167 1504.52,155.483 1515.26,131.875 1526,129.646 1536.74,194.801 
  1547.48,197.591 1558.22,215.164 1568.97,217.109 1579.71,171.668 1590.45,209.692 1601.19,175.391 1611.93,179.097 1622.67,150.533 1633.41,140.067 1644.15,138.658 
  1654.9,143.681 1665.64,179.361 1676.38,176.087 1687.12,186.279 1697.86,226.724 1708.6,207.626 1719.34,196.248 1730.08,197.993 1740.83,241.658 1751.57,208.167 
  1762.31,199.991 1773.05,206.806 1783.79,211.06 1794.53,226.768 1805.27,190.149 1816.01,222.025 1826.76,249.389 1837.5,231.321 1848.24,201.706 1858.98,210.671 
  1869.72,211.056 1880.46,187.091 1891.2,188.841 1901.94,181.145 1912.69,170.259 1923.43,197.052 1934.17,235.007 1944.91,254.542 1955.65,239.817 1966.39,260.02 
  1977.13,326.629 1987.87,309.851 1998.62,311.711 2009.36,315.067 2020.1,320.07 2030.84,294.618 2041.58,334.718 2052.32,319.074 2063.06,286.266 2073.81,241.502 
  2084.55,230.13 2095.29,241.21 2106.03,255.184 2116.77,265.522 2127.51,222.802 2138.25,174.062 2148.99,206.226 2159.74,214.485 2170.48,240.828 2181.22,276.769 
  2191.96,282.3 2202.7,296.442 2213.44,283.641 2224.18,248.355 2234.92,264.096 2245.67,277.833 2256.41,281.202 2267.15,303.197 2277.89,283.244 2288.63,266.494 
  
  "/>
<polyline clip-path="url(#clip9902)" style="stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none" points="
  151.118,1479.5 161.859,1478.99 172.6,1476.85 183.341,1470.49 194.083,1457.7 204.824,1446.73 215.565,1434.53 226.306,1416.23 237.048,1417.34 247.789,1395.89 
  258.53,1391.8 269.272,1389.57 280.013,1371.88 290.754,1369.08 301.495,1357.94 312.237,1357.08 322.978,1346.78 333.719,1333.58 344.46,1334.07 355.202,1319.8 
  365.943,1300.96 376.684,1296.74 387.425,1257.27 398.167,1285.27 408.908,1275.35 419.649,1278.03 430.391,1272.43 441.132,1248.96 451.873,1229.76 462.614,1225.45 
  473.356,1186.8 484.097,1106.47 494.838,1124.6 505.579,1185.77 516.321,1179.66 527.062,1196.11 537.803,1169.36 548.545,1115.55 559.286,1020.9 570.027,1136.46 
  580.768,778.633 591.51,938.601 602.251,816.658 612.992,746.247 623.733,951.508 634.475,896.836 645.216,906.262 655.957,842.415 666.699,761.319 677.44,821.902 
  688.181,997.704 698.922,742.446 709.664,720.421 720.405,731.531 731.146,887.86 741.887,800.812 752.629,857.384 763.37,975.792 774.111,727.962 784.853,862.288 
  795.594,664.552 806.335,718.563 817.076,642.088 827.818,783.681 838.559,746.667 849.3,833.655 860.041,848.858 870.783,805.037 881.524,591.129 892.265,598.215 
  903.007,804.675 913.748,901.57 924.489,738.641 935.23,559.44 945.972,701.247 956.713,626.069 967.454,749.197 978.195,518.329 988.937,872.653 999.678,718.631 
  1010.42,724.657 1021.16,596.056 1031.9,572.971 1042.64,745.314 1053.38,740.23 1064.13,702.89 1074.87,617.516 1085.61,473.176 1096.35,370.442 1107.09,552.219 
  1117.83,408.708 1128.57,287.259 1139.31,552.502 1150.06,359.832 1160.8,456.978 1171.54,494.887 1182.28,502.692 1193.02,365.681 1203.76,542.675 1214.5,428.889 
  1225.24,600.142 1235.99,837.948 1246.73,589.578 1257.47,342.996 1268.21,338.794 1278.95,499.607 1289.69,770.429 1300.43,633.571 1311.17,452.691 1321.92,528.129 
  1332.66,611.723 1343.4,779.459 1354.14,675.616 1364.88,652.241 1375.62,868.896 1386.36,842.401 1397.1,728.27 1407.85,767.273 1418.59,669.814 1429.33,578.902 
  1440.07,509.598 1450.81,703.562 1461.55,352.029 1472.29,474.239 1483.04,626.789 1493.78,649.976 1504.52,490.423 1515.26,588.638 1526,926.614 1536.74,608.044 
  1547.48,817.458 1558.22,818.84 1568.97,489.651 1579.71,646.143 1590.45,262.74 1601.19,431.005 1611.93,451.566 1622.67,478.224 1633.41,197.495 1644.15,408.161 
  1654.9,556.803 1665.64,288.817 1676.38,354.722 1687.12,386.681 1697.86,221.516 1708.6,290.271 1719.34,316.415 1730.08,347.549 1740.83,355.074 1751.57,311.135 
  1762.31,486.58 1773.05,292.107 1783.79,407.868 1794.53,315.688 1805.27,493.611 1816.01,531.996 1826.76,683.17 1837.5,355.919 1848.24,680.662 1858.98,844.542 
  1869.72,618.72 1880.46,924.921 1891.2,699.587 1901.94,446.455 1912.69,475.072 1923.43,483.51 1934.17,594.359 1944.91,262.268 1955.65,452.336 1966.39,386.146 
  1977.13,646.902 1987.87,286.066 1998.62,400.583 2009.36,403.847 2020.1,499.073 2030.84,464.911 2041.58,374.691 2052.32,678.632 2063.06,527.645 2073.81,287.536 
  2084.55,1096.12 2095.29,629.152 2106.03,398.813 2116.77,304.141 2127.51,337.753 2138.25,229.557 2148.99,346.002 2159.74,258.958 2170.48,194.015 2181.22,352.699 
  2191.96,461.345 2202.7,599.237 2213.44,360.936 2224.18,421.765 2234.92,240.497 2245.67,536.23 2256.41,610.574 2267.15,552.698 2277.89,358.502 2288.63,305.138 
  
  "/>
<path clip-path="url(#clip9900)" d="
M1676.96 327.952 L2280.76 327.952 L2280.76 146.512 L1676.96 146.512  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<polyline clip-path="url(#clip9900)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1676.96,327.952 2280.76,327.952 2280.76,146.512 1676.96,146.512 1676.96,327.952 
  "/>
<polyline clip-path="url(#clip9900)" style="stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none" points="
  1700.96,206.992 1844.96,206.992 
  "/>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;" transform="rotate(0, 1868.96, 224.492)" x="1868.96" y="224.492">Mean Policy</text>
</g>
<polyline clip-path="url(#clip9900)" style="stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none" points="
  1700.96,267.472 1844.96,267.472 
  "/>
<g clip-path="url(#clip9900)">
<text style="fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;" transform="rotate(0, 1868.96, 284.972)" x="1868.96" y="284.972">Stochastic Policy</text>
</g>
</svg>
<p>and save the logged results to the Experiment</p><pre><code class="language-julia">for (k, v) in get(lg)
    exper[k] = v
end
finish!(exper); # flushes everything to disk</code></pre><pre><code class="language-none">[ Info: Experiment saved to /tmp/hopper_example.jlso</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../MPPI/">« Running a simple controller</a><a class="docs-footer-nextpage" href="../visualize/">Visualizing Results »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 13 January 2020 20:04">Monday 13 January 2020</span>. Using Julia version 1.3.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
